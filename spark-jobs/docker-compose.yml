# spark-submit --master spark://spark-master:7077 /opt/spark/work-dir/jobs/sample.py

version: '3.7'

services:
    spark-master:
        image: leloimr/spark-master:latest # bitnami/spark:3.5.1
        container_name: spark-master
        
        build:
          context: .
          dockerfile: ./Dockerfile
        command: bin/spark-class org.apache.spark.deploy.master.Master
        ports:
            - "9090:8080"
            - "7077:7077"
        volumes:
            - ./jobs/:/opt/spark/work-dir/jobs/
        restart: always

    spark-worker-1:
        image: leloimr/spark-master:latest
        command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
        depends_on:
            - spark-master
        environment:
            SPARK_MODE: worker
            SPARK_WORKER_CORES: 1
            SPARK_WORKER_MEMORY: 1g
            SPARK_MASTER_URL: spark://spark-master:7077
 
volumes:
    spark-master-data:
        external: false